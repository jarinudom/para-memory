# PARA Memory System for AI Agents

A structured, decaying memory system based on Tiago Forte's PARA method. Give your AI agent persistent memory that organizes facts by entity, tracks relationships, and naturally forgets less-important information over time.

## ğŸš€ Quick Start

```bash
# 1. Clone or copy to your workspace
cd ~/your-workspace
cp -r /path/to/para-memory ./skills/para-memory

# 2. Install requirements
brew install ollama        # For local LLM
ollama serve
ollama pull qwen2.5:7b     # Or llama3.2
clawdhub install qmd       # For search indexing

# 3. Run setup
./skills/para-memory/scripts/setup.sh

# 4. Test checkpoint (requires Ollama running)
python3 scripts/memory_checkpoint.py manual
```

## âš ï¸ Requirements (Local/Offline)

This skill is designed for **local, private operation**:

| Tool | Purpose | Install |
|------|---------|---------|
| **Ollama** | Local LLM for fact extraction | `brew install ollama && ollama serve` |
| **QMD** | Search indexing (BM25 + vectors) | `clawdhub install qmd` |
| **Python + openai** | Script dependencies | `pip install openai` |

No external APIs, no cloud services, no data leaves your machine.

## ğŸ“– What It Does

### The Problem
AI agents wake up with amnesia every session. They need external memory to maintain relationships, track projects, and remember preferences.

### The Solution
PARA Memory provides:

1. **Structured Storage** - Facts organized by entity type (people, companies, projects, resources)
2. **Atomic Facts** - Each piece of information is a discrete, trackable unit
3. **Natural Decay** - Old, unused facts fade from active summaries (but aren't deleted)
4. **Automatic Extraction** - LLM analyzes conversations and extracts durable facts

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Conversation   â”‚ â”€â”€â–¶ â”‚   Checkpoint     â”‚ â”€â”€â–¶ â”‚   PARA Store    â”‚
â”‚  (Daily Notes)  â”‚     â”‚   (LLM Extract)  â”‚     â”‚   (facts.json)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                         â”‚
                                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Agent Reads   â”‚ â—€â”€â”€ â”‚   Summary.md     â”‚ â—€â”€â”€ â”‚   Decay System  â”‚
â”‚   (Hot/Warm)    â”‚     â”‚   (Regenerated)  â”‚     â”‚   (Weekly)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Memory Tiers

| Tier | Emoji | Access Age | Behavior |
|------|-------|------------|----------|
| Hot | ğŸ”¥ | 0-7 days | Always in summary |
| Warm | ğŸŒ¡ï¸ | 8-30 days | In summary, lower priority |
| Cold | â„ï¸ | 31+ days | Omitted from summary, kept in facts.json |

**Frequency Resistance:** Facts accessed 10+ times stay Hot regardless of age.

## ğŸ“ Directory Structure

After setup, your workspace will have:

```
workspace/
â”œâ”€â”€ para/
â”‚   â”œâ”€â”€ projects/           # Active work
â”‚   â”œâ”€â”€ areas/
â”‚   â”‚   â”œâ”€â”€ people/         # People you interact with
â”‚   â”‚   â””â”€â”€ companies/      # Organizations
â”‚   â”œâ”€â”€ resources/          # Topics of interest
â”‚   â””â”€â”€ archives/           # Inactive items
â”œâ”€â”€ memory/
â”‚   â””â”€â”€ YYYY-MM-DD.md       # Daily conversation logs
â””â”€â”€ scripts/
    â”œâ”€â”€ memory_checkpoint.py
    â””â”€â”€ memory-decay.py
```

## âš™ï¸ Configuration

Set these environment variables (or edit the scripts):

```bash
export PARA_WORKSPACE=/path/to/workspace
export PARA_OLLAMA_URL=http://localhost:11434/v1
export PARA_MODEL=qwen2.5:7b
```

## ğŸ”§ Commands

### Checkpoint (Extract Facts)

```bash
# Run manually
python3 scripts/memory_checkpoint.py manual

# Cron (every 30 min)
*/30 * * * * cd /workspace && python3 scripts/memory_checkpoint.py cron
```

### Decay (Update Summaries)

```bash
# Quick update (just regenerate summaries)
python3 scripts/memory-decay.py --quick

# Full cycle (weekly)
python3 scripts/memory-decay.py
```

## ğŸ“ Example Entity

**para/areas/people/alice/facts.json:**
```json
{
  "entity": "alice",
  "entity_type": "people", 
  "facts": [
    {
      "id": "ali-001",
      "fact": "Lead engineer at Acme Corp",
      "category": "context",
      "status": "active",
      "accessCount": 5,
      "lastAccessed": "2026-01-31",
      "relatedEntities": ["areas/companies/acme-corp"]
    }
  ]
}
```

**para/areas/people/alice/summary.md:**
```markdown
# Alice

## ğŸ”¥ Hot (Recent/Frequent)
- ğŸ“ **context**: Lead engineer at Acme Corp

## ğŸ”— Connected To
- areas/companies/acme-corp
```

## ğŸ” Troubleshooting

### "No recent context" error
- Ensure `memory/YYYY-MM-DD.md` exists with today's date
- The checkpoint script reads from daily notes

### LLM not responding
- Check Ollama is running: `ollama list`
- Test API: `curl http://localhost:11434/v1/models`

### Facts not appearing in summary
- Run decay: `python3 scripts/memory-decay.py --quick`
- Check `facts.json` has `status: "active"`

## ğŸ“š Full Documentation

See [SKILL.md](./SKILL.md) for complete documentation including:
- All configuration options
- Entity schema details
- Integration guides
- Fact categories reference

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Submit a pull request

## ğŸ“„ License

MIT License - Use freely, attribution appreciated.
